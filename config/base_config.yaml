path:
  train: ../data/train_dataset
  predict: ../data/test_dataset

model:
  name: klue/roberta-base

tokenizer:
  max_length: 256
  padding: max_length
  stride: 128
  return_token_type_ids: False # False for Roberta models
  return_overflowing_tokens: True
  return_offsets_mapping: True

optimizer: # default AdamW
  learning_rate: 1e-5
  weight_decay: 0
  adam_beta1: 0.9 # The beta1 hyperparameter for the AdamW optimizer.
  adam_beta2: 0.999 # The beta2 hyperparameter for the AdamW optimizer.
  adam_epsilon: 1e-8 # The epsilon hyperparameter for the AdamW optimizer.
  lr_scheduler_type: linear
  warmup_ratio: 0.5

criterion:
  nmae: ce

train:
  output_dir: ./saved_models/
  num_train_epochs: 5
  do_train: True
  do_eval: True
  do_predict: False
  overwrite_output_dir: False
  fp16: False

utils:
  seed: 42
  num_workers: 4
  overwrite_cache: False
  max_answer_length: 30
  top_k: 3

wandb:
  team: next-level-potato # team account name
  project: MRC # project name
  name: LWJ # 실험자 명
  info: baseline # 실험명
