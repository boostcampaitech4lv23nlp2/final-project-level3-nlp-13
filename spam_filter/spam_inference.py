from sklearn.metrics import precision_recall_fscore_support, accuracy_score
import torch
import datasets
import sys
import argparse
import pandas as pd
import numpy as np
import datetime
import pytz
from datasets import Dataset, DatasetDict,load_dataset
from omegaconf import OmegaConf
from transformers import AutoModel, AutoTokenizer, BertTokenizer
from data_loader.data_loaders import ClassificationDataset
from transformers import (
    BertForSequenceClassification, 
    Trainer, 
    TrainingArguments, 
    ElectraForSequenceClassification,
    ElectraTokenizer,
    DataCollatorForTokenClassification,
    )
    
def main(config):
    if config.spam.model.name =="klue/bert-base":
        print("ğŸ¤¬ get BERT model...")
        tokenizer = AutoTokenizer.from_pretrained(config.spam.path.inference_model)
        model = BertForSequenceClassification.from_pretrained(config.spam.path.inference_model)
    else:
        print("ğŸ¤¬ get Electra model...")
        tokenizer = ElectraTokenizer.from_pretrained(config.spam.path.inference_model)
        model = ElectraForSequenceClassification.from_pretrained(config.spam.path.inference_model)
    def sentences_predict(sent):        
        model.eval()
        tokenized_sent = tokenizer(
                sent,
                return_tensors="pt",
                truncation=True,
                add_special_tokens=True,
                max_length=128
        )
        #tokenized_sent.to(device)
        
        with torch.no_grad():# ê·¸ë¼ë””ì—”íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
            outputs = model(
                input_ids=tokenized_sent['input_ids'],
                attention_mask=tokenized_sent['attention_mask'],
                token_type_ids=tokenized_sent['token_type_ids']
                )

        logits = outputs[0]
        logits = logits.detach().cpu().numpy()
        result = np.argmax(logits)
        return sent, result

    print(sentences_predict("ì‹œë°œ")) #1
    print(sentences_predict("ì‹œë°œë¡¬ì•„")) #1
    print(sentences_predict("ã……ã…‚")) #1
    print(sentences_predict("ì§€ë„")) #1
    print(sentences_predict("ã…ˆã„¹")) #1
    print(sentences_predict("ì¡´ë‚˜ ë¬´ì„­ë„¤")) #1
    print(sentences_predict("ê°œê¼´ ì”¨ë°œ ã…‹ã…‹")) #1
    print(sentences_predict("ì‹œë°œ ì¼ê²Œì´ë“¤ ì´ì œ ëŸ¬ë¸Œì¸ ì•„ì‹œì•„ ê°•ì œë¡œ ì°ê²Œë˜ë…¸ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")) #1
    print(sentences_predict("ì´ë¯¸ í•œë‚¨ ì™€ê¾¸ëŠ”........ ììŒ....!!!!")) #1
    print(sentences_predict("ê²Œì´ë„ ì¢†ê°™ê³  ë ˆì¦ˆë„ ì¢†ê°™ê³  ë™ì„±ì•  ì”¨ë°œë…„ë†ˆë“¤ì€ ì˜›ë‚ ì²˜ëŸ¼ ì•„ìš°ìŠˆë¹„ì¸  ê°€ìŠ¤ì‹¤ì— ì‹¸ê·¸ë¦¬ ëª¨ì•„ë†“ê³  ë…ê°€ìŠ¤ ì‚´í¬í•´ì„œì• ë¯¸ì• ë¹„ ë³´ëŠ”ì•ì—ì„œ ê³ í†µìŠ¤ëŸ½ê³  ì”ì¸í•˜ê²Œ ì£½ì—¬ì•¼ëœë‹¤")) #1
    print(sentences_predict("ì§±ê°œ ì£¼ì‘ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")) #1
    print(sentences_predict("ê²Œì´ì•¼ ìš©ê¸°ì‚¬ë©´ ë“œë˜ê³¤ ì‚¬ì—­í•˜ê³ ìˆë…¸?")) #1
    print(sentences_predict("ì§€ë°©ê²ƒë“¤ì´")) #1
    print(sentences_predict("ã„¹ã…‡ ê°œì¢ƒê°™ì€ í˜ë¯¸ë¯¼êµ­ ì§„ì§œìš”ì¦˜ ì¢Œì¢€ ë‹¬ì°½ ë¶„íƒ•ë…„ë“¤ ë‚¨ì´ˆì— ì˜¤ì§€ê²Œ í’€ì—ˆë”ë§Œì• êµ­í•˜ë©´ì„œ ë…¸ì˜ˆì²˜ëŸ¼ ì‚´ì•„ê°€ë¼ê³  ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")) #1
    print(sentences_predict("ì†ìƒí•˜ê³  ë¹¡ì³")) #1

    print(sentences_predict("ì†ìƒí•˜ê³  ì§œì¦ë‚˜ ì£½ê² ìŒ ì§„ì§œ")) #0
    print(sentences_predict("í ë¶ˆìŒí•´")) #0
    print(sentences_predict("ì–´ì œ í•˜ë£¨ì¢…ì¼ ì†ìƒí•˜ê³  ë‚˜ë‹ˆê¹Œ")) #0
    print(sentences_predict("ë°ì€ íšŒìƒ‰ì´ ìœ í–‰ì´ë¼ë˜ë°")) #0
    print(sentences_predict("ë­ ì–´ì©Œë¼ê³ ")) #0
    print(sentences_predict("í˜ë¯¸ë‹ˆìŠ¤íŠ¸ì˜ ëª¨ìŠµì´ë‹¤")) #0
    print(sentences_predict("ì¡¸ë¼ ê·€ì—½ë‹¤....")) #0
    print(sentences_predict("ì„¸ìƒì´ ë°‰ë‹¤")) #0
    print(sentences_predict("í•­ìƒ ëŒ“ê¸€ë“¤ì´ ì™œ ì´ëŸ´ê¹Œ ì˜ì•„í–ˆëŠ”ë° ì§€ê¸ˆì€ ìƒí™©ì´ ì´ë ‡ê²Œ ë°”ë€Œë‹¤ë‹ˆ. ì¤‘êµ­ ì°¸ ë¬´ì„­ê³  í™”ë‚˜ë„¤.")) #0

    
if __name__ == "__main__":
    # config ì„¤ì •
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="base_config")

    args, _ = parser.parse_known_args()
    config = OmegaConf.load(f"./config/{args.config}.yaml")

    # fix random seeds for reproducibility
    SEED = 123
    torch.manual_seed(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(SEED)
    main(config)
