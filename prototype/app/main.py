import argparse
import sys

from fastapi import FastAPI
from omegaconf import OmegaConf
from pydantic import BaseModel

sys.path.append("..")  # Adds higher directory to python modules path.
from datetime import datetime

from chatbot.generator.util import Generator
from chatbot.pipeline.data_pipeline import DataPipeline
from chatbot.retriever.elastic_retriever import ElasticRetriever
from classes import UserTweet
from omegaconf import OmegaConf
from pytz import timezone
from spam_filter.spam_filter import SpamFilter
import re

parser = argparse.ArgumentParser()
parser.add_argument("--config", "-c", type=str, default="base_config")
args, _ = parser.parse_known_args()
config = OmegaConf.load(f"config/{args.config}.yaml")

app = FastAPI()


class User_input(BaseModel):
    sentence: str
    max_len: int
    top_k: int
    top_p: float


# fmt: off
special_tokens = ["BTS", "bts", "RM", "rm", "ì§„", "ê¹€ì„ì§„", "ì„ì§„", "ê¹€ë‚¨ì¤€", "ë‚¨ì¤€", "ìŠˆê°€", "ë¯¼ìœ¤ê¸°", "ìœ¤ê¸°", "ì œì´í™‰", "ì •í˜¸ì„", "ì§€ë¯¼", "ë°•ì§€ë¯¼", "ë·”", "ê¹€íƒœí˜•", "íƒœí˜•", "V", "ì •êµ­", "ì „ì •êµ­", "ì•„ë¯¸", "ë¹…íˆíŠ¸", "í•˜ì´ë¸Œ", "ì•„ë¯¸", "ë³´ë¼í•´" ] #TO-Do
# fmt: on

today = datetime.now(timezone("Asia/Seoul")).strftime("%m%d")
generator = Generator(config)

def islanguage(text):
    language = re.compile('[ã„±-ã…£ê°€-í£a-zA-Z]')
    if language.search(text):
        return True
    return False

@app.post("/input", description="ì£¼ë¬¸ì„ ìš”ì²­í•©ë‹ˆë‹¤")
async def make_chat(data: User_input):
    text = data.dict()["sentence"]
    max_len = data.dict()["max_len"]
    top_k = data.dict()["top_k"]
    top_p = data.dict()["top_p"]

    is_spam = SpamFilter().sentences_predict(text)  # 1ì´ë©´ ìŠ¤íŒ¸, 0ì´ë©´ ì•„ë‹˜
    if not text.strip():
        return "ì…ë ¥ì´ ì—†ì–´"
    elif not islanguage(text):
        return "ë¬¸ìë¥¼ ì…ë ¥í•´ì¤˜"
    elif is_spam:
        return "ê¸€ì„..."
    else:
        # 3-1. ì „ì²˜ë¦¬ & ë¦¬íŠ¸ë¦¬ë²„
        data_pipeline = DataPipeline(log_dir="log", special_tokens=special_tokens)
        elastic_retriever = ElasticRetriever()
        retrieved = elastic_retriever.return_answer(text)
        print("ğŸ”¥ ", data_pipeline)
        print("ğŸ”¥ğŸ”¥ ", text)
        print("ğŸ”¥ğŸ”¥ğŸ”¥ ", retrieved.query)

        if retrieved.query is not None:
            my_answer = data_pipeline.correct_grammar(retrieved)
        else:
            # 3-2. ì „ì²˜ë¦¬ ì—†ì´? ìƒì„±ëª¨ë¸
            my_answer = generator.get_answer(text, 1, max_len, top_k, top_p)

            if "<account>" in my_answer:
                my_answer = my_answer.replace("<account>", "ìœ ì €")

    # log: user message + screen name + bot answer
    data_pipeline.log(
        new_entries=[UserTweet(screen_name="ìµëª…ì˜ ìœ ì €", message=text, reply=my_answer)],
        save_name=today,
    )

    # inference_result = generator.get_answer(text, 1, max_len, top_k, top_p)

    return my_answer
