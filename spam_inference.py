from sklearn.metrics import precision_recall_fscore_support, accuracy_score
import torch
import datasets
import sys
import argparse
import pandas as pd
import numpy as np
import datetime
import pytz
from datasets import Dataset, DatasetDict,load_dataset
from omegaconf import OmegaConf
from transformers import AutoModel, AutoTokenizer, BertTokenizer
from data_loader.data_loaders import SingleSentDataset
from transformers import BertForSequenceClassification, Trainer, TrainingArguments

def main(config):
    print("ğŸ¤¬ get model...")
    tokenizer = AutoTokenizer.from_pretrained(config.spam.model.name)
    model = BertForSequenceClassification.from_pretrained(config.spam.path.model)

    def sentences_predict(sent):        
        model.eval()
        tokenized_sent = tokenizer(
                sent,
                return_tensors="pt",
                truncation=True,
                add_special_tokens=True,
                max_length=128
        )
        #tokenized_sent.to(device)
        
        with torch.no_grad():# ê·¸ë¼ë””ì—”íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
            outputs = model(
                input_ids=tokenized_sent['input_ids'],
                attention_mask=tokenized_sent['attention_mask'],
                token_type_ids=tokenized_sent['token_type_ids']
                )

        logits = outputs[0]
        logits = logits.detach().cpu().numpy()
        result = np.argmax(logits)
        return result

    print(sentences_predict("ì§±ê°œ ì£¼ì‘ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹")) #1
    print(sentences_predict("ì–´ì œ í•˜ë£¨ì¢…ì¼ ì†ìƒí•˜ê³  ë‚˜ë‹ˆê¹Œ")) #0
    print(sentences_predict("ê²Œì´ì•¼ ìš©ê¸°ì‚¬ë©´ ë“œë˜ê³¤ ì‚¬ì—­í•˜ê³ ìˆë…¸?")) #1
    print(sentences_predict("ë°ì€ íšŒìƒ‰ì´ ìœ í–‰ì´ë¼ë˜ë°")) #0
    print(sentences_predict("ì§€ë°©ê²ƒë“¤ì´")) #1

if __name__ == "__main__":
    # config ì„¤ì •
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="base_config")

    args, _ = parser.parse_known_args()
    config = OmegaConf.load(f"./config/{args.config}.yaml")

    # fix random seeds for reproducibility
    SEED = 123
    torch.manual_seed(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(SEED)
    main(config)