import argparse
import os
import random

import numpy as np
import torch
from omegaconf import OmegaConf
from tokenizers import SentencePieceBPETokenizer
from transformers import AutoModel, AutoModelForSeq2SeqLM, AutoTokenizer, GPT2LMHeadModel, PreTrainedTokenizerFast
from utils.util import Chatbot_utils


def main(config):
    print("ğŸ”¥ get model...")
    if "gpt" in config.model.name_or_path:
        print("ğŸ”¥ gpt")
        tokenizer = PreTrainedTokenizerFast.from_pretrained(
            config.model.name_or_path,
            bos_token="</s>",
            eos_token="</s>",
            sep_token="<sep>",
            unk_token="<unk>",
            pad_token="<pad>",
            mask_token="<mask>",
        )
        model = GPT2LMHeadModel.from_pretrained(config.model.name_or_path)
        model.resize_token_embeddings(len(tokenizer))
    elif (
        "bart" in config.model.name_or_path
        or "bart".upper() in config.model.name_or_path
        or "t5" in config.model.name_or_path
        or "t5".upper() in config.model.name_or_path
    ):
        print("ğŸ”¥ Enc-Dec")
        tokenizer = PreTrainedTokenizerFast.from_pretrained(config.model.name_or_path)
        model = AutoModelForSeq2SeqLM.from_pretrained(config.model.name_or_path)
        model.resize_token_embeddings(len(tokenizer))
    model.to("cuda")

    print("ğŸ”¥ get input...")
    generator = Chatbot_utils(config, tokenizer, model)
    gen_num = 5
    generator.get_answer("ì•ˆë…•?", gen_num, config.tokenizer.max_length)
    generator.get_answer("ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ.", gen_num, config.tokenizer.max_length)
    generator.get_answer("ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?", gen_num, config.tokenizer.max_length)
    generator.get_answer("ì—¬ìì¹œêµ¬ ì„ ë¬¼ ì¶”ì²œí•´ì¤˜.", gen_num, config.tokenizer.max_length)
    generator.get_answer("ì•ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ì´ ì–´ë–»ê²Œ ë°œì „í•˜ê²Œ ë ê¹Œìš”?", gen_num, config.tokenizer.max_length)
    generator.get_answer("ì´ì œ ê·¸ë§Œ ìˆ˜ì—… ëë‚´ì.", gen_num, config.tokenizer.max_length)


if __name__ == "__main__":
    # config ì„¤ì •
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", "-c", type=str, default="base_config")

    args, _ = parser.parse_known_args()
    config = OmegaConf.load(f"./config/{args.config}.yaml")

    # seed ì„¤ì •
    SEED = 123
    random.seed(SEED)
    np.random.seed(SEED)
    os.environ["PYTHONHASHSEED"] = str(SEED)
    torch.manual_seed(SEED)
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)  # if use multi-GPU
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    main(config)
